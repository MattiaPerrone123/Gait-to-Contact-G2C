{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDIues9mg8cd"
   },
   "source": [
    "### Modules to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import onnxruntime as ort\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functions.utilities import process_output_data, load_and_stack_processed_images\n",
    "from functions.data_processing import process_files, prepare_train_test_dataloaders\n",
    "from functions.model import TimeSeriesToImageModelCont\n",
    "from functions.train_validate import train_and_validate, get_input_sample, load_model_onnx\n",
    "from functions.evaluate import evaluate_model_onnx\n",
    "from functions.hp_tuning import run_optuna_study\n",
    "from functions.metrics import (\n",
    "    calculate_blob_extents,\n",
    "    calculate_areas,\n",
    "    calculate_mape,\n",
    "    compute_angles,\n",
    "    compute_centroids,\n",
    "    compute_centroid_distances,\n",
    "    calculate_nrmse,\n",
    "    calculate_nmi,\n",
    "    calculate_ssim,\n",
    "    determine_dynamic_roi,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYWe375Ho3T5"
   },
   "source": [
    "### Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set paths and parameters\n",
    "curr_path=os.getcwd()\n",
    "path_data=os.path.join(curr_path, \"Results\")\n",
    "path_output=os.path.join(curr_path, \"wearscar_processed_100x100\")\n",
    "inputs=[\"ap\", \"fe\", \"force\", \"ie\"]\n",
    "output=\"wearscar\"\n",
    "m=100\n",
    "n=100\n",
    "plot=True\n",
    "save=True\n",
    "save_suffix=\"wearscar_processed_100x100\"\n",
    "file_suffix=f\"{m}x{n}\"\n",
    "\n",
    "#Process input and output files\n",
    "all_inputs, all_output, columns_output=process_files(path_data, inputs, output)\n",
    "\n",
    "all_input_ap=all_inputs[\"ap\"]\n",
    "all_input_fe=all_inputs[\"fe\"]\n",
    "all_input_force=all_inputs[\"force\"]\n",
    "all_input_ie=all_inputs[\"ie\"]\n",
    "\n",
    "#Process and save the output data\n",
    "process_output_data(columns_output, path_data, save_suffix, m, n, plot, save)\n",
    "\n",
    "#Load and stack processed images\n",
    "all_data_output=load_and_stack_processed_images(path_output, m, n, file_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mattia\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "#Prepare DataLoaders for training and testing\n",
    "train_dataloader, test_dataloader=prepare_train_test_dataloaders(\n",
    "    all_input_ap, all_input_fe, all_input_force, all_input_ie,\n",
    "    all_data_output, inputs, test_size=0.2, random_state=15, batch_size=4\n",
    ")\n",
    "\n",
    "\n",
    "#Set up the model\n",
    "model=TimeSeriesToImageModelCont()\n",
    "optimizer=optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion=nn.MSELoss()\n",
    "num_epochs=1000\n",
    "onnx_checkpoint_path='best_model_g2c.onnx'\n",
    "\n",
    "input_sample=get_input_sample(train_dataloader, batch_size=4)\n",
    "\n",
    "#Train and validate the model, saving the best model as ONNX\n",
    "train_losses, val_losses=train_and_validate(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    num_epochs=num_epochs,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    checkpoint_path=onnx_checkpoint_path,\n",
    "    input_sample=input_sample,\n",
    "    plot_every=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and computing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model on test data\n",
    "onnx_session=load_model_onnx(onnx_checkpoint_path)\n",
    "predictions_test, ground_truth_test=evaluate_model_onnx(\n",
    "    session=onnx_session, \n",
    "    dataloader=test_dataloader, \n",
    "    threshold=5e-4\n",
    ")\n",
    "\n",
    "#Parameters\n",
    "image_shape=predictions_test.shape[2:]\n",
    "thresh_zero=5e-4\n",
    "\n",
    "#Calculate blob extents\n",
    "x_ext_pred, y_ext_pred, x_ext_ground, y_ext_ground=calculate_blob_extents(predictions_test, ground_truth_test, thresh_zero)\n",
    "\n",
    "#Calculate MAPE for extents\n",
    "mape_x_first=calculate_mape(x_ext_ground['first'], x_ext_pred['first'])\n",
    "mape_x_second=calculate_mape(x_ext_ground['second'], x_ext_pred['second'])\n",
    "mape_y_first=calculate_mape(y_ext_ground['first'], y_ext_pred['first'])\n",
    "mape_y_second=calculate_mape(y_ext_ground['second'], y_ext_pred['second'])\n",
    "\n",
    "#Calculate areas\n",
    "areas_pred, areas_ground=calculate_areas(predictions_test, ground_truth_test)\n",
    "\n",
    "#Calculate MAPE for areas\n",
    "mape_non_weight_first=calculate_mape(areas_ground['non_weighted_first'], areas_pred['non_weighted_first'])\n",
    "mape_non_weight_second=calculate_mape(areas_ground['non_weighted_second'], areas_pred['non_weighted_second'])\n",
    "mape_weight_first=calculate_mape(areas_ground['weighted_first'], areas_pred['weighted_first'])\n",
    "mape_weight_second=calculate_mape(areas_ground['weighted_second'], areas_pred['weighted_second'])\n",
    "\n",
    "\n",
    "#Compute centroids\n",
    "centroids_pred, centroids_ground=compute_centroids(predictions_test, ground_truth_test)\n",
    "\n",
    "# Compute centroid distances\n",
    "distances=compute_centroid_distances(centroids_pred, centroids_ground, image_shape)\n",
    "\n",
    "#Compute angles\n",
    "angles=compute_angles(centroids_pred, centroids_ground, image_shape)\n",
    "\n",
    "#Compute errors for angles\n",
    "mape_non_weight_first_angle=calculate_mape(angles['non_weighted']['ground'], angles['non_weighted']['pred'])\n",
    "mape_weight_first_angle=calculate_mape(angles['weighted']['ground'], angles['weighted']['pred'])\n",
    "\n",
    "nrmse_non_weight_first_angle=calculate_nrmse(angles['non_weighted']['ground'], angles['non_weighted']['pred'])\n",
    "nrmse_weight_first_angle=calculate_nrmse(angles['weighted']['ground'], angles['weighted']['pred'])\n",
    "\n",
    "\n",
    "#Calculate NMI and SSIM for a specific region\n",
    "region_of_interest=(20, 85, 5, 30)\n",
    "dynamic_roi=determine_dynamic_roi(predictions_test, thresh_zero)\n",
    "\n",
    "nmi_scores_region=calculate_nmi(predictions_test, ground_truth_test, region=region_of_interest)\n",
    "ssim_scores_region=calculate_ssim(predictions_test, ground_truth_test, region=region_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: run hyperparameter tuning\n",
    "study=run_optuna_study(train_dataloader, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
